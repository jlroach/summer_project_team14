# summer_project_team14
Human trafficking data analysis for team 14 summer term

Datasets were gathered from multiple sources in an attempt to determine if a model could be successfully developed to accurately predict occurrences of human trafficking in a given country based on a variety of socio-economic and political variables.

In total, 23 datasets were used with 22 being predictors and the 23rd as the response. All but one of the predictor sets were compiled by the UN with the remaining being a calculated government corruption score which was generated by an organization which developed the method. The response set came from the Counter-Trafficking Data Collaborative.

Data was loaded into a SQL database to be compiled into a single set. The result is the consoliData.csv file.

Due to time constraints and inexperience with the subject matter, the response was reduced to a single variable which is a combination of the count of country of citizenship and country of exploitation. These were summed to create a single count value per country.

The csv file was loaded into R, and models were trained and tested using various methods all within the caret package.

Since the resulting dataset is small, multiple resampling and modeling methods were attempted including repeated CV, leave one out, and leave group out for the resampling and PLS, PCA, LM, random forest, and ridge for the models.

As can be seen in the presentation file, there were no models which were able to successfully predict the occurrences based on the data available. Given additional time and a wider range of data, it is possible that an accurate model could be developed.
